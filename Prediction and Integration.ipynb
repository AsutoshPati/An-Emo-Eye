{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e272cc-50e8-4973-8d01-510b6cf5877e",
   "metadata": {},
   "source": [
    "# Senitment Prediction for Robo Eye Animation\n",
    "\n",
    "The project, involves a dynamic robot eye animation displayed on a 0.96\" OLED screen that changes based on the sentiment of text input provided by the user. The hardware controller used for this project is the CAP10 Pratham, a made-in-India board. This project offers a unique way to integrate emotional intelligence into robotics, enabling bots to visually express emotions in response to user interactions.\n",
    "\n",
    "**Author:** Asutosh Pati ([https://www.linkedin.com/in/asutoshpati/](https://www.linkedin.com/in/asutoshpati/))  \n",
    "**Date:** 21-Aug-2024  \n",
    "**Versions:**  \n",
    "- V1.0: Initial Release\n",
    "- V1.1: Change communication method from Serial to API call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c71e6-6f87-4e58-aa35-b903d1dc0f2e",
   "metadata": {},
   "source": [
    "### Install & Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571f9b0-0625-4253-a652-f8fad30e0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93eb5763-ed33-43fc-8d64-de08a50bc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0967b52f-19ce-4487-9152-c9fedf0e0a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\asuto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asuto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74d071-15c3-400a-b8b2-8dd8daeaf55c",
   "metadata": {},
   "source": [
    "### Preprocess the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7955f7d4-c230-4823-8a1a-3a1e100e8c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer= WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c026a9d5-61ec-4413-acae-6673125957dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh, yes! i have ssen that.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lower_case(text):\n",
    "    text = text.split()\n",
    "    text = [y.lower() for y in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "lower_case(\"Oh, Yes! I have ssen that.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb11f84-3b96-4eff-989c-8618c0f2346a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have you visited '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "remove_urls(\"Have you visited https://www.google.co.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c70339ed-f75f-465b-b3a8-3f2047e3746e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Are you sure It s amazing'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuations(text):\n",
    "    # Remove punctuations\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,،-./:;<=>؟?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = text.replace('؛',\"\", )\n",
    "    \n",
    "    # remove extra whitespace\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text =  \" \".join(text.split())\n",
    "    return text.strip()\n",
    "\n",
    "remove_punctuations(\"Are you sure; It's amazing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf779b8-b8d9-4812-85ef-97a727470297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Have you seen the prime minister's speech at  am\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text\n",
    "\n",
    "remove_numbers(\"Have you seen the prime minister's speech at 10 am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912d0732-5f30-4105-9b4d-d6c523877ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I good boy; true'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stop_words(text):\n",
    "    text = [i for i in str(text).split() if i not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "remove_stop_words(\"I am a very good boy; is it true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065e597e-89ac-42ad-87b0-b49f64c7568c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love to watch Footbal. What do you like to do?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(y) for y in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "lemmatization(\"I love to watch Footbal. What do you like to do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d13442e-032d-4b24-ba3c-4799af1414bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arise awake stop goal reached swami vivekananda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = lower_case(sentence)\n",
    "    sentence = remove_urls(sentence)\n",
    "    sentence = remove_punctuations(sentence)\n",
    "    sentence = remove_numbers(sentence)\n",
    "    sentence = remove_stop_words(sentence)\n",
    "    sentence = lemmatization(sentence)\n",
    "    return sentence\n",
    "\n",
    "preprocess_sentence(\"Arise, awake, and stop not until the goal is reached. - Swami Vivekananda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fd89f-ee4c-4fb8-badb-e5523086f971",
   "metadata": {},
   "source": [
    "### Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1901c5b-9cc5-477c-8c44-dadb1cc8038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.3.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import label encoder created during training\n",
    "\n",
    "le = None\n",
    "with open(\"./model/label_encoder.pkl\",'rb') as file:\n",
    "    le = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36800ce-793a-4b48-9b8c-1106afa56bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokenizer created during training\n",
    "\n",
    "tokenizer = None\n",
    "with open(\"./model/tokenizer.json\") as file:\n",
    "    tokenizer_json = file.read()\n",
    "    tokenizer = tokenizer_from_json(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10ea2e4a-fe29-480b-81a6-c68aab125b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 229, 200)          2865000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 229, 512)          935936    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 229, 256)          656384    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 229, 256)          394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 229, 128)          164352    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirecti  (None, 128)               98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5115502 (19.51 MB)\n",
      "Trainable params: 2250502 (8.58 MB)\n",
      "Non-trainable params: 2865000 (10.93 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import the pre-trained model\n",
    "\n",
    "model_path = \"./model/Sentiment_analysis_Eng-V3.h5\"\n",
    "model = load_model(model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862de7c-74a0-46a9-af0f-b1c78bca6332",
   "metadata": {},
   "source": [
    "### Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fde69741-7e22-4493-b162-ed6fa6400e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels ['fear', 'sadness', 'joy', 'anger', 'love', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "652cbe92-cc00-4ad0-a1e1-9d5088261988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "['fear'] : 0.32459312677383423\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_emotion(text):\n",
    "    sentence = preprocess_sentence(text)\n",
    "    \n",
    "    sentence = tokenizer.texts_to_sequences([sentence])\n",
    "    sentence = pad_sequences(sentence, maxlen=229, truncating='pre')\n",
    "    \n",
    "    result = le.inverse_transform(np.argmax(model.predict(sentence), axis=-1))\n",
    "    proba =  np.max(model.predict(sentence))\n",
    "\n",
    "    # class_predict =  np.max(model.predict(sentence))\n",
    "    # print(class_predict)\n",
    "    \n",
    "    print(f\"{result} : {proba}\\n\\n\")\n",
    "    \n",
    "    return result[0]\n",
    "\n",
    "extract_emotion(\"Hurray!! My Model Got 93% Accuracy, Connect With me https://www.linkedin.com/in/asutoshpati/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4519592-9138-4d12-b9b6-c026c3e316bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentences = [\n",
    "    \"He's over the moon about being accepted to the university\",\n",
    "    \"Your point on this certain matter made me outrageous, how can you say so? This is insane.\",\n",
    "    \"I can't do it, I'm not ready to lose anything, just leave me alone\",\n",
    "    \"Merlin's beard harry, you can cast the Patronus charm! I'm amazed!\",\n",
    "    \"I am amazed, that you do it.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da4d96a-162c-41c1-9c9d-2ac38a950284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He's over the moon about being accepted to the university\n",
      "1/1 [==============================] - 0s 303ms/step\n",
      "1/1 [==============================] - 0s 299ms/step\n",
      "['joy'] : 0.8274199962615967\n",
      "\n",
      "\n",
      "joy\n",
      "\n",
      "\n",
      "\n",
      "Your point on this certain matter made me outrageous, how can you say so? This is insane.\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 483ms/step\n",
      "['anger'] : 0.48978257179260254\n",
      "\n",
      "\n",
      "anger\n",
      "\n",
      "\n",
      "\n",
      "I can't do it, I'm not ready to lose anything, just leave me alone\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "['fear'] : 0.3876217007637024\n",
      "\n",
      "\n",
      "fear\n",
      "\n",
      "\n",
      "\n",
      "Merlin's beard harry, you can cast the Patronus charm! I'm amazed!\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "['surprise'] : 0.9352065324783325\n",
      "\n",
      "\n",
      "surprise\n",
      "\n",
      "\n",
      "\n",
      "I am amazed, that you do it.\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "['surprise'] : 0.2998327612876892\n",
      "\n",
      "\n",
      "surprise\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in example_sentences:\n",
    "    print(sentence)\n",
    "    print(extract_emotion(sentence))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94267a4f-564b-4685-98f0-7f29cd7777dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_mood_mapping = {\"fear\": \"F\", \"sadness\": \"S\", \"joy\": \"H\", \"anger\": \"A\", \"love\": \"L\", \"surprise\": \"N\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb5ed65-5713-4346-b1d3-0ff1c0813f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_mood(mood):\n",
    "    url = 'http://192.168.1.1'\n",
    "\n",
    "    try:\n",
    "        payload = {'mood': mood}\n",
    "        response = requests.get(url, params=payload)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(\"Request sent to bot\")\n",
    "            return None\n",
    "        else:\n",
    "            print('Error:', response.status_code)\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('Error:', e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b31b45a-2af9-4597-8bd3-6c7757a76a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few examples that you can try\n",
    "# Hey, I have a good news for you. are you amazed! - surprise\n",
    "# Its your birthday, I have gift for you. aren't you happy. - joy\n",
    "# What you've done has left me heartbroken. - sadness\n",
    "# Are you afraid that I know what you have done ? - fear\n",
    "# For your nasty work I am going to scold you - anger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2951cf57-c464-46b9-b320-adc998d9f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your text:  Hey, I have a good news for you. are you amazed!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "['surprise'] : 0.6928766369819641\n",
      "\n",
      "\n",
      "Error: HTTPConnectionPool(host='192.168.1.1', port=80): Max retries exceeded with url: /?mood=N (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000210F0931C10>, 'Connection to 192.168.1.1 timed out. (connect timeout=None)'))\n"
     ]
    }
   ],
   "source": [
    "# Don't forget to connect with CAP10 before running this cell\n",
    "\n",
    "text = input(\"Enter your text: \")\n",
    "emotion = extract_emotion(text)\n",
    "mood = emotion_mood_mapping.get(emotion)\n",
    "send_mood(mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa04d4-5970-40b5-aee5-c6ceb18477c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
